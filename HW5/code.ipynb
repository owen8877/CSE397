{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Import dependencies\n",
    "import dolfin as dl\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.environ.get('HIPPYLIB_DIR', \"../../\"))\n",
    "\n",
    "from hippylib import *\n",
    "\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "logging.getLogger('FFC').setLevel(logging.WARNING)\n",
    "logging.getLogger('UFL').setLevel(logging.WARNING)\n",
    "dl.set_log_active(False)\n",
    "np.random.seed(seed=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Class HessianOperator to perform Hessian apply to a vector\n",
    "class HessianOperator():\n",
    "    cgiter = 0\n",
    "\n",
    "    def __init__(self, R, Wmm, C, A, adj_A, W, Wum, bc0, use_gaussnewton=False):\n",
    "        self.R = R\n",
    "        self.Wmm = Wmm\n",
    "        self.C = C\n",
    "        self.A = A\n",
    "        self.adj_A = adj_A\n",
    "        self.W = W\n",
    "        self.Wum = Wum\n",
    "        self.bc0 = bc0\n",
    "        self.use_gaussnewton = use_gaussnewton\n",
    "\n",
    "        # incremental state\n",
    "        self.du = dl.Vector()\n",
    "        self.A.init_vector(self.du, 0)\n",
    "\n",
    "        #incremental adjoint\n",
    "        self.dp = dl.Vector()\n",
    "        self.adj_A.init_vector(self.dp, 0)\n",
    "\n",
    "        # auxiliary vector\n",
    "        self.Wum_du = dl.Vector()\n",
    "        self.Wum.init_vector(self.Wum_du, 1)\n",
    "\n",
    "    def init_vector(self, v, dim):\n",
    "        self.R.init_vector(v, dim)\n",
    "\n",
    "    # Hessian performed on v, output as generic vector y\n",
    "    def mult(self, v, y):\n",
    "        self.cgiter += 1\n",
    "        y.zero()\n",
    "        if self.use_gaussnewton:\n",
    "            self.mult_GaussNewton(v, y)\n",
    "        else:\n",
    "            self.mult_Newton(v, y)\n",
    "\n",
    "    # define (Gauss-Newton) Hessian apply H * v\n",
    "    def mult_GaussNewton(self, v, y):\n",
    "\n",
    "        #incremental forward\n",
    "        rhs = -(self.C * v)\n",
    "        self.bc0.apply(rhs)\n",
    "        dl.solve(self.A, self.du, rhs)\n",
    "\n",
    "        #incremental adjoint\n",
    "        rhs = - (self.W * self.du)\n",
    "        self.bc0.apply(rhs)\n",
    "        dl.solve(self.adj_A, self.dp, rhs)\n",
    "\n",
    "        # Misfit term\n",
    "        self.C.transpmult(self.dp, y)\n",
    "\n",
    "        if self.R:\n",
    "            Rv = self.R * v\n",
    "            y.axpy(1, Rv)\n",
    "\n",
    "    # define (Newton) Hessian apply H * v\n",
    "    def mult_Newton(self, v, y):\n",
    "\n",
    "        #incremental forward\n",
    "        rhs = -(self.C * v)\n",
    "        self.bc0.apply(rhs)\n",
    "        dl.solve(self.A, self.du, rhs)\n",
    "\n",
    "        #incremental adjoint\n",
    "        rhs = -(self.W * self.du) - self.Wum * v\n",
    "        self.bc0.apply(rhs)\n",
    "        dl.solve(self.adj_A, self.dp, rhs)\n",
    "\n",
    "        #Misfit term\n",
    "        self.C.transpmult(self.dp, y)\n",
    "\n",
    "        self.Wum.transpmult(self.du, self.Wum_du)\n",
    "        y.axpy(1., self.Wum_du)\n",
    "\n",
    "        y.axpy(1., self.Wmm * v)\n",
    "\n",
    "        #Reg/Prior term\n",
    "        if self.R:\n",
    "            y.axpy(1., self.R * v)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def id_str(nx, gamma, useTV, noise, useGaussNewton):\n",
    "    return f'n={nx:d};gamma={gamma:.1e};{\"TV\" if useTV else \"TN\"};noise={noise:.2f};{\"mixed\" if callable(useGaussNewton) else \"GN\" if useGaussNewton else \"N\"}'\n",
    "\n",
    "\n",
    "def AddDiffInverseProblem(nx, ny, gamma, v, morozov=False, plot=True, useTV=True, TVeps=0.1, m0_val=8, maxiter=50,\n",
    "                          useGaussNewton=lambda iter, maxiter: iter < maxiter / 2, noise_level=0.01):\n",
    "    mesh = dl.UnitSquareMesh(nx, ny)\n",
    "    Vm = dl.FunctionSpace(mesh, 'Lagrange', 1)\n",
    "    Vu = dl.FunctionSpace(mesh, 'Lagrange', 2)\n",
    "\n",
    "    # The true and initial guess inverted parameter\n",
    "    mtrue = dl.interpolate(dl.Expression('8. - 4.*(pow(x[0] - 0.5,2) + pow(x[1] - 0.5,2) < pow(0.2,2) )', degree=5), Vm)\n",
    "\n",
    "    # define function for state and adjoint\n",
    "    u = dl.Function(Vu)\n",
    "    m = dl.Function(Vm)\n",
    "    p = dl.Function(Vu)\n",
    "\n",
    "    # define Trial and Test Functions\n",
    "    u_trial, m_trial, p_trial = dl.TrialFunction(Vu), dl.TrialFunction(Vm), dl.TrialFunction(Vu)\n",
    "    u_test, m_test, p_test = dl.TestFunction(Vu), dl.TestFunction(Vm), dl.TestFunction(Vu)\n",
    "\n",
    "    # initialize input functions\n",
    "    f = dl.interpolate(dl.Expression('std::max(0.5, exp(-25*(pow(x[0]-0.7, 2)+pow(x[1]-0.7, 2))))', degree=5), Vu)\n",
    "    k = dl.Constant(1.0)\n",
    "    u0 = dl.Constant(0.0)\n",
    "\n",
    "    # set up dirichlet boundary conditions\n",
    "    def boundary(x, on_boundary):\n",
    "        return on_boundary\n",
    "\n",
    "    bc_state = dl.DirichletBC(Vu, u0, boundary)\n",
    "    bc_adj = dl.DirichletBC(Vu, dl.Constant(0.), boundary)\n",
    "\n",
    "    # weak form for setting up the synthetic observations\n",
    "    def a_state_gen(u, m, p_hat):\n",
    "        return (dl.inner(k * dl.grad(u), dl.grad(p_hat)) * dl.dx\n",
    "                + dl.inner(v, dl.grad(u)) * p_hat * dl.dx\n",
    "                + 100 * dl.exp(m) * u ** 3 * p_hat * dl.dx\n",
    "                - f * p_hat * dl.dx)\n",
    "\n",
    "    a_true_not_used = (dl.inner(k * dl.grad(u_trial), dl.grad(u_test)) * dl.dx\n",
    "                       + dl.inner(v, dl.grad(u_trial)) * u_test * dl.dx)\n",
    "    L_true_not_used = f * u_test * dl.dx\n",
    "\n",
    "    def forward_solver(_u, m):\n",
    "        dl.solve(a_state_gen(_u, m, u_test) == 0, _u, bc_state,\n",
    "                 solver_parameters={'newton_solver': {'relative_tolerance': 1e-5, 'maximum_iterations': 200}})\n",
    "\n",
    "    # solve the forward/state problem to generate synthetic observations\n",
    "    A_true_not_used, b_true_not_used = dl.assemble_system(a_true_not_used, L_true_not_used, bc_state)\n",
    "\n",
    "    utrue = dl.Function(Vu)\n",
    "    # dl.solve(A_true_not_used, utrue.vector(), b_true_not_used)\n",
    "    forward_solver(utrue, mtrue)\n",
    "\n",
    "    ud = dl.Function(Vu)\n",
    "    ud.assign(utrue)\n",
    "\n",
    "    # perturb state solution and create synthetic measurements ud\n",
    "    # ud = u + ||u||/SNR * random.normal\n",
    "    MAX = ud.vector().norm(\"linf\")\n",
    "    noise = dl.Vector()\n",
    "    A_true_not_used.init_vector(noise, 1)\n",
    "    noise.set_local(noise_level * MAX * np.random.normal(0, 1, len(ud.vector().get_local())))\n",
    "    bc_adj.apply(noise)\n",
    "\n",
    "    ud.vector().axpy(1., noise)\n",
    "\n",
    "    # define cost function\n",
    "    def cost(u, ud, m, gamma):\n",
    "        if useTV:\n",
    "            g = dl.grad(m)\n",
    "            reg = gamma * dl.assemble(dl.sqrt(dl.inner(g, g) + TVeps) * dl.dx)\n",
    "        else:\n",
    "            reg = 0.5 * gamma * dl.assemble(dl.inner(dl.grad(m), dl.grad(m)) * dl.dx)\n",
    "        misfit = 0.5 * dl.assemble((u - ud) ** 2 * dl.dx)\n",
    "\n",
    "        return [reg + misfit, misfit, reg]\n",
    "\n",
    "    # weak form for setting up the state equation\n",
    "    # a_state = (dl.inner(k * dl.grad(u_trial), dl.grad(u_test)) * dl.dx\n",
    "    #           + dl.dot(v, dl.grad(u_trial)) * u_test * dl.dx\n",
    "    #           + 100 * dl.exp(m) * u_trial ** 3 * u_test * dl.dx)\n",
    "    # L_state = f * u_test * dl.dx\n",
    "\n",
    "    # weak form for setting up the adjoint equation\n",
    "    a_adj = (dl.inner(k * dl.grad(p_trial), dl.grad(p_test)) * dl.dx\n",
    "             + dl.dot(v, dl.grad(p_test)) * p_trial * dl.dx\n",
    "             + 300 * dl.exp(m) * u ** 2 * p_test * p_trial * dl.dx)\n",
    "    L_adj = -dl.inner(u - ud, p_test) * dl.dx\n",
    "\n",
    "    # weak form for setting up the increment state equation\n",
    "    a_inc_state = (dl.inner(k * dl.grad(u_trial), dl.grad(u_test)) * dl.dx\n",
    "                   + dl.dot(v, dl.grad(u_trial)) * u_test * dl.dx\n",
    "                   + 300 * dl.exp(m) * u ** 3 * u_trial * u_test * dl.dx)\n",
    "    L_inc_state_not_used = u_test * dl.dx\n",
    "\n",
    "    # weak form for gradient\n",
    "    CTvarf = 100 * dl.exp(m) * m_test * u ** 3 * p * dl.dx\n",
    "    if useTV:\n",
    "        gradRvarf = ((gamma / dl.sqrt(dl.inner(dl.grad(m), dl.grad(m)) + TVeps)) *\n",
    "                     dl.inner(dl.grad(m), dl.grad(m_test)) * dl.dx)\n",
    "    else:\n",
    "        gradRvarf = gamma * dl.inner(dl.grad(m), dl.grad(m_test)) * dl.dx\n",
    "\n",
    "    # L^2 weighted inner product\n",
    "    M_varf = dl.inner(m_trial, m_test) * dl.dx\n",
    "    M = dl.assemble(M_varf)\n",
    "\n",
    "    m0 = dl.interpolate(dl.Constant(m0_val), Vm)\n",
    "    m.assign(m0)\n",
    "\n",
    "    # solve state equation\n",
    "    # state_A, state_b = dl.assemble_system(a_state, L_state, bc_state)\n",
    "    # dl.solve (state_A, u.vector(), state_b)\n",
    "    forward_solver(u, m)\n",
    "\n",
    "    nb.multi1_plot([ud, u], ['ud', 'u'])\n",
    "    plt.show()\n",
    "\n",
    "    # evaluate cost\n",
    "    [cost_old, misfit_old, reg_old] = cost(u, ud, m, gamma)\n",
    "\n",
    "    #Hessian varfs\n",
    "    W_varf = dl.inner(u_trial, u_test) * dl.dx\n",
    "    if useTV:\n",
    "        _g = dl.grad(m)\n",
    "        _g2 = dl.inner(_g, _g)\n",
    "        _g_trial = dl.grad(m_trial)\n",
    "        _g_test = dl.grad(m_test)\n",
    "        R_varf = gamma / dl.sqrt(_g2 + TVeps) ** 3 * (\n",
    "                dl.inner(_g_trial, _g_test) * (_g2 + TVeps)\n",
    "                - dl.inner(_g, _g_trial) * dl.inner(_g, _g_test)\n",
    "        ) * dl.dx\n",
    "    else:\n",
    "        R_varf = dl.Constant(gamma) * dl.inner(dl.grad(m_trial), dl.grad(m_test)) * dl.dx\n",
    "\n",
    "    C_varf = 100 * dl.exp(m) * m_trial * u ** 3 * u_test * dl.dx\n",
    "    Wum_varf = 300 * dl.exp(m) * m_trial * u ** 2 * p_test * p * dl.dx\n",
    "    Wmm_varf = 100 * dl.exp(m) * m_trial * m_test * u ** 3 * p * dl.dx\n",
    "\n",
    "    # Assemble constant matrices\n",
    "    W = dl.assemble(W_varf)\n",
    "    R = dl.assemble(R_varf)\n",
    "\n",
    "    # define parameters for the optimization\n",
    "    tol = 1e-8\n",
    "    c = 1e-4\n",
    "\n",
    "    # initialize iter counters\n",
    "    iter = 1\n",
    "    total_cg_iter = 0\n",
    "    converged = False\n",
    "\n",
    "    # initializations\n",
    "    g, m_delta = dl.Vector(), dl.Vector()\n",
    "    R.init_vector(m_delta, 0)\n",
    "    R.init_vector(g, 0)\n",
    "\n",
    "    m_prev = dl.Function(Vm)\n",
    "\n",
    "    id = id_str(nx, gamma, useTV, noise_level, useGaussNewton)\n",
    "    import pathlib\n",
    "    pathlib.Path(f'/home/fenics/shared/hw5/plot/{id}').mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(f'/home/fenics/shared/hw5/data/{id}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    checkpoints = []\n",
    "\n",
    "    print(\"Nit   CGit   cost          misfit        reg           sqrt(-G*D)    ||grad||       alpha  tolcg\")\n",
    "\n",
    "    while iter < maxiter and not converged:\n",
    "\n",
    "        # solve the adoint problem\n",
    "        adjoint_A, adjoint_RHS = dl.assemble_system(a_adj, L_adj, bc_adj)\n",
    "        dl.solve(adjoint_A, p.vector(), adjoint_RHS)\n",
    "\n",
    "        # evaluate the  gradient\n",
    "        MG = dl.assemble(CTvarf + gradRvarf)\n",
    "\n",
    "        # calculate the L^2 norm of the gradient\n",
    "        dl.solve(M, g, MG)\n",
    "        grad2 = g.inner(MG)\n",
    "        gradnorm = np.sqrt(grad2)\n",
    "\n",
    "\n",
    "        # set the CG tolerance (use Eisenstat–Walker termination criterion)\n",
    "        if iter == 1:\n",
    "            gradnorm_ini = gradnorm\n",
    "        tolcg = min(0.5, np.sqrt(gradnorm / gradnorm_ini))\n",
    "\n",
    "        # assemble W_um and W_mm\n",
    "        C = dl.assemble(C_varf)\n",
    "        Wum = dl.assemble(Wum_varf)\n",
    "        Wmm = dl.assemble(Wmm_varf)\n",
    "\n",
    "        # define the Hessian apply operator (with preconditioner)\n",
    "        inc_state_A, _ = dl.assemble_system(a_inc_state, L_inc_state_not_used, bc_state)\n",
    "        R = dl.assemble(R_varf)\n",
    "        Hess_Apply = HessianOperator(R, Wmm, C, inc_state_A, adjoint_A, W, Wum, bc_adj,\n",
    "                                     use_gaussnewton=useGaussNewton(iter, maxiter) if callable(useGaussNewton) else useGaussNewton)\n",
    "        P = R + 0.1 * gamma * M\n",
    "        Psolver = dl.PETScKrylovSolver(\"cg\", amg_method())\n",
    "        Psolver.set_operator(P)\n",
    "\n",
    "        solver = CGSolverSteihaug()\n",
    "        solver.set_operator(Hess_Apply)\n",
    "        solver.set_preconditioner(Psolver)\n",
    "        solver.parameters[\"rel_tolerance\"] = tolcg\n",
    "        solver.parameters[\"zero_initial_guess\"] = True\n",
    "        solver.parameters[\"print_level\"] = -1\n",
    "        solver.parameters[\"max_iter\"] = 30\n",
    "\n",
    "        # solve the Newton system H a_delta = - MG\n",
    "        solver.solve(m_delta, -MG)\n",
    "        total_cg_iter += Hess_Apply.cgiter\n",
    "\n",
    "        # if plot and iter % 10 == 0:\n",
    "        #     g_form = dl.Function(Vm)\n",
    "        #     g_form.vector()[:] = g\n",
    "        #     m_delta_form = dl.Function(Vm)\n",
    "        #     m_delta_form.vector()[:] = m_delta\n",
    "        #     nb.multi1_plot([p, g_form], ['p', 'g'], same_colorbar=False)\n",
    "        #     nb.multi1_plot([m_delta_form, m], ['m_delta', 'm'], same_colorbar=False)\n",
    "        #     plt.show()\n",
    "\n",
    "        # linesearch\n",
    "        alpha = 1\n",
    "        descent = 0\n",
    "        no_backtrack = 0\n",
    "        m_prev.assign(m)\n",
    "        while descent == 0 and no_backtrack < 10:\n",
    "            m.vector().axpy(alpha, m_delta)\n",
    "\n",
    "            # solve the state/forward problem\n",
    "            # state_A, state_b = dl.assemble_system(a_state, L_state, bc_state)\n",
    "            # dl.solve(state_A, u.vector(), state_b)\n",
    "            forward_solver(u, m)\n",
    "\n",
    "            # evaluate cost\n",
    "            [cost_new, misfit_new, reg_new] = cost(u, ud, m, gamma)\n",
    "\n",
    "            # check if Armijo conditions are satisfied\n",
    "            if cost_new < cost_old + alpha * c * MG.inner(m_delta):\n",
    "                cost_old = cost_new\n",
    "                descent = 1\n",
    "            else:\n",
    "                no_backtrack += 1\n",
    "                alpha *= 0.5\n",
    "                m.assign(m_prev)  # reset a\n",
    "\n",
    "        # calculate sqrt(-G * D)\n",
    "        graddir = np.sqrt(- MG.inner(m_delta))\n",
    "\n",
    "        sp = \"\"\n",
    "        print(\"%2d %2s %2d %3s %8.5e %1s %8.5e %1s %8.5e %1s %8.5e %1s %8.5e %1s %5.2f %1s %5.3e\" %\n",
    "              (iter, sp, Hess_Apply.cgiter, sp, cost_new, sp, misfit_new, sp, reg_new, sp,\n",
    "               graddir, sp, gradnorm, sp, alpha, sp, tolcg))\n",
    "\n",
    "        # check for convergence\n",
    "        if gradnorm < tol and iter > 1:\n",
    "            converged = True\n",
    "            print(\"Newton's method converged in \", iter, \"  iterations\")\n",
    "            print(\"Total number of CG iterations: \", total_cg_iter)\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        checkpoints.append({'u': u.vector().get_local(),\n",
    "                            'm': m.vector().get_local(),\n",
    "                            'p': p.vector().get_local()})\n",
    "\n",
    "    if not converged:\n",
    "        print(\"Newton's method did not converge in \", maxiter, \" iterations\")\n",
    "\n",
    "    if plot:\n",
    "        nb.multi1_plot([mtrue, m], [\"mtrue\", \"m\"])\n",
    "        plt.show()\n",
    "\n",
    "    np.savez(f'/home/fenics/shared/hw5/data/{id}/data.npz', checkpoints=checkpoints, m0_val=m0_val,\n",
    "             gamma=gamma, useTV=useTV, mtrue=mtrue.vector().get_local(), iter=iter, total_cg_iter=total_cg_iter)\n",
    "\n",
    "    Mstate = dl.assemble(u_trial * u_test * dl.dx)\n",
    "    noise_norm2 = noise.inner(Mstate * noise)\n",
    "    if not morozov:\n",
    "        Hmisfit = HessianOperator(None, Wmm, C, inc_state_A, adjoint_A, W, Wum, bc_adj, use_gaussnewton=False)\n",
    "        k = 50\n",
    "        p = 20\n",
    "\n",
    "        Omega = MultiVector(m.vector(), k + p)\n",
    "        parRandom.normal(1., Omega)\n",
    "        lmbda, evecs = doublePassG(Hmisfit, P, Psolver, Omega, k)\n",
    "\n",
    "        plt.plot(range(0, k), lmbda, 'b*', range(0, k + 1), np.ones(k + 1), '-r')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('number')\n",
    "        plt.ylabel('eigenvalue')\n",
    "        plt.show()\n",
    "\n",
    "        nb.plot_eigenvectors(Vm, evecs, mytitle=\"Eigenvector\", which=[0, 1, 2, 5, 10, 15])\n",
    "        plt.savefig(f'/home/fenics/shared/hw5/plot/{id}/eigenvectors.jpg')\n",
    "        plt.show()\n",
    "\n",
    "    return Vm.dim(), iter, total_cg_iter, noise_norm2, cost_new, misfit_new, reg_new"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-9, morozov=False,\n",
    "                          plot=True, useTV=False, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-7, morozov=True,\n",
    "                          plot=True, useTV=False, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-8, morozov=True,\n",
    "                          plot=True, useTV=False, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-10, morozov=True,\n",
    "                          plot=True, useTV=False, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-9, morozov=False,\n",
    "                          plot=True, useTV=True, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-7, morozov=True,\n",
    "                          plot=True, useTV=True, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-8, morozov=True,\n",
    "                          plot=True, useTV=True, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "    AddDiffInverseProblem(nx=20, ny=20, v=dl.Constant((1., 0.)), gamma=1e-10, morozov=True,\n",
    "                          plot=True, useTV=True, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for nx in 40, 80:\n",
    "    for useTV in True, False:\n",
    "        for gamma in 1e-10, 1e-9, 1e-8, 1e-7:\n",
    "            ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "                AddDiffInverseProblem(nx=nx, ny=nx, v=dl.Constant((1., 0.)), gamma=gamma, morozov=True,\n",
    "                                      plot=True, useTV=useTV, TVeps=0.001, m0_val=8, useGaussNewton=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in optimized data and plot them\n",
    "m_true_dict = dict()\n",
    "m_recovered_dict = dict()\n",
    "iters_dict = dict()\n",
    "cg_iters_dict = dict()\n",
    "\n",
    "for useTV in True, False:\n",
    "    m_recovered_dict[useTV] = dict()\n",
    "    iters_dict[useTV] = dict()\n",
    "    cg_iters_dict[useTV] = dict()\n",
    "    for nx in 20, 40, 80:\n",
    "        m_true_dict[nx] = dict()\n",
    "        m_recovered_dict[useTV][nx] = dict()\n",
    "        iters_dict[useTV][nx] = dict()\n",
    "        cg_iters_dict[useTV][nx] = dict()\n",
    "\n",
    "        mesh = dl.UnitSquareMesh(nx, nx)\n",
    "        Vm = dl.FunctionSpace(mesh, 'Lagrange', 1)\n",
    "        for gamma in 1e-10, 1e-9, 1e-8, 1e-7:\n",
    "            id = id_str(nx, gamma, useTV, 0.01, True)\n",
    "            with np.load(f'/home/fenics/shared/hw5/data/{id}/data.npz') as data:\n",
    "                checkpoint_vec = data['checkpoints']\n",
    "\n",
    "                m_recovered = dl.Function(Vm)\n",
    "                m_recovered.vector()[:] = checkpoint_vec[-1]['m']\n",
    "\n",
    "                m_true = dl.Function(Vm)\n",
    "                m_true.vector()[:] = data['mtrue']\n",
    "\n",
    "                m_true_dict[nx] = m_true\n",
    "                m_recovered_dict[useTV][nx][gamma] = m_recovered\n",
    "                iters_dict[useTV][nx][gamma] = data['iter']\n",
    "                cg_iters_dict[useTV][nx][gamma] = data['total_cg_iter']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for nx in 20, 40, 80:\n",
    "    nb.plot(m_true_dict[nx], vmin=4, vmax=8)\n",
    "    plt.title('$m_{true}' + f',n={nx:d}$')\n",
    "    plt.savefig(f'/home/fenics/shared/hw5/plot/m_true_n_{nx:d}.jpg', bbox_inches='tight', transparent=\"True\", pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "for useTV in True, False:\n",
    "    for nx in 20, 40, 80:\n",
    "        for gamma in 1e-10, 1e-9, 1e-8, 1e-7:\n",
    "            id = id_str(nx, gamma, useTV, 0.01, True)\n",
    "\n",
    "            m_recovered = m_recovered_dict[useTV][nx][gamma]\n",
    "            iter = iters_dict[useTV][nx][gamma]\n",
    "            cg_iter = cg_iters_dict[useTV][nx][gamma]\n",
    "            nb.plot(m_recovered, vmin=4, vmax=8, colorbar=False)\n",
    "            plt.title(f'$\\\\beta$={gamma:.0e}, {iter}/{cg_iter} iters')\n",
    "            plt.savefig(f'/home/fenics/shared/hw5/plot/{id}/m_recovered.jpg', bbox_inches='tight', transparent=\"True\", pad_inches=0)\n",
    "            plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nx = 40\n",
    "useTV = False\n",
    "for gamma in 1e-10, 1e-9, 1e-8, 1e-7:\n",
    "    for noise_level in 0.01, 0.1:\n",
    "        for useGaussNewton in False, True:\n",
    "            ndof, niter, ncgiter, noise_norm2, cost, misfit, reg = (\n",
    "                AddDiffInverseProblem(nx=nx, ny=nx, v=dl.Constant((1., 0.)), gamma=gamma, morozov=True,\n",
    "                                      plot=True, useTV=useTV, m0_val=8, useGaussNewton=useGaussNewton,\n",
    "                                      noise_level=noise_level, maxiter=100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in optimized data and plot them\n",
    "nx = 40\n",
    "useTV = False\n",
    "mesh = dl.UnitSquareMesh(nx, nx)\n",
    "Vm = dl.FunctionSpace(mesh, 'Lagrange', 1)\n",
    "\n",
    "m_recovered_dict_2 = dict()\n",
    "iters_dict_2 = dict()\n",
    "cg_iters_dict_2 = dict()\n",
    "\n",
    "for gamma in 1e-10, 1e-9, 1e-8, 1e-7:\n",
    "    m_recovered_dict_2[gamma] = dict()\n",
    "    iters_dict_2[gamma] = dict()\n",
    "    cg_iters_dict_2[gamma] = dict()\n",
    "\n",
    "    for noise_level in 0.01, 0.1:\n",
    "        m_recovered_dict_2[gamma][noise_level] = dict()\n",
    "        iters_dict_2[gamma][noise_level] = dict()\n",
    "        cg_iters_dict_2[gamma][noise_level] = dict()\n",
    "\n",
    "        for useGaussNewton in False, True:\n",
    "            id = id_str(nx, gamma, useTV, noise_level, useGaussNewton)\n",
    "            with np.load(f'/home/fenics/shared/hw5/data/{id}/data.npz') as data:\n",
    "                checkpoint_vec = data['checkpoints']\n",
    "\n",
    "                m_recovered = dl.Function(Vm)\n",
    "                m_recovered.vector()[:] = checkpoint_vec[-1]['m']\n",
    "\n",
    "                m_true = dl.Function(Vm)\n",
    "                m_true.vector()[:] = data['mtrue']\n",
    "\n",
    "                m_recovered_dict_2[gamma][noise_level][useGaussNewton] = m_recovered\n",
    "                iters_dict_2[gamma][noise_level][useGaussNewton] = data['iter']\n",
    "                cg_iters_dict_2[gamma][noise_level][useGaussNewton] = data['total_cg_iter']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for gamma in 1e-10, 1e-9, 1e-8, 1e-7:\n",
    "    for noise_level in 0.01, 0.1:\n",
    "        for useGaussNewton in False, True:\n",
    "            id = id_str(nx, gamma, useTV, noise_level, useGaussNewton)\n",
    "\n",
    "            m_recovered = m_recovered_dict_2[gamma][noise_level][useGaussNewton]\n",
    "            iter = iters_dict_2[gamma][noise_level][useGaussNewton]\n",
    "            cg_iter = cg_iters_dict_2[gamma][noise_level][useGaussNewton]\n",
    "            nb.plot(m_recovered, vmin=4, vmax=8, colorbar=False)\n",
    "            plt.title(f'$\\\\beta$={gamma:.0e}, {iter}/{cg_iter} iters')\n",
    "            plt.savefig(f'/home/fenics/shared/hw5/plot/{id}/m_recovered.jpg', bbox_inches='tight', transparent=\"True\", pad_inches=0)\n",
    "            plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gammas = np.array([1e-10, 1e-9, 1e-8, 1e-7])\n",
    "def plot_wrapper(ax, iter_dict, noise_level, useGaussNewton, style):\n",
    "    iters = np.array([iter_dict[gamma][noise_level][useGaussNewton] for gamma in gammas])\n",
    "    ax.plot(gammas, iters, style, label=f'{int(noise_level*100):d}% noise, {\"Gauss-Newton\" if useGaussNewton else \"Newton\"}')\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 5), squeeze=True)\n",
    "for noise_level, color in (0.01, 'r'), (0.1, 'b'):\n",
    "    for useGaussNewton, style in (True, '-'), (False, '--'):\n",
    "        plot_wrapper(axs[0], iters_dict_2, noise_level, useGaussNewton, color+style)\n",
    "        plot_wrapper(axs[1], cg_iters_dict_2, noise_level, useGaussNewton, color+style)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set(xscale='log', xlabel='$\\\\beta$', ylabel='# iteration')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.savefig(f'/home/fenics/shared/hw5/plot/itr.jpg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}